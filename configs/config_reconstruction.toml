DEBUG = false

task = "reconstruction" # options: forecasting, anomaly_detection, semantic_segmentation, segmentation, pretraining
model = "timellm"          # options: timellm, gpt4ts, dlinear, patchtst, fedformer, timesnet

history_len = 128
pred_len = 128


[data]
dataset = "ECG"
mode = "multivariate"
cols = "all"
normalize = true
step = 64


[training]
epochs = 10
batch_size = 16
optimizer = "ranger"
learning_rate = 0.001
dropout = 0.1
loss = "mse"

eval_metric = "mse"
eval_metric_direction = "min"


[models.timellm]
d_model = 32
d_ff = 64
n_heads = 8
num_tokens = 1000
covariate_mode = "add"                # options: univariate, concat, add, interleave, independent, independent-weighted
embedding_downsample_mode = "linear"  # options: linear, truncate, average

[models.timellm.patching]
patch_len = 16
stride = 8

[models.timellm.llm]
enabled = true
llm = "state-spaces/mamba-1.4b-hf"
load_in_4bit = false
load_in_8bit = false
llm_layers = 36


[models.gpt4ts]
d_ff = 768
d_model = 768
gpt_layers = 6
train_mlp = false

[models.gpt4ts.patching]
patch_len = 1
stride = 1


[models.dlinear]
moving_avg = 25
individual = false


[models.patchtst]
e_layers = 3
d_model = 128
d_ff = 256
n_heads = 8
covariate_mode = "independent"

[models.patchtst.patching]
patch_len = 16
stride = 8


[models.fedformer]
d_model = 128
d_ff = 256
n_heads = 8
version = "fourier"
mode_select = "random"
modes = 32
moving_avg = 25
activation = "gelu"
e_layers = 2
d_layers = 1
label_len = 0


[models.timesnet]
e_layers = 3
d_model = 32
d_ff = 32
num_kernels = 6
top_k = 3


[setup]
seed = 0
device = "auto"
dtype = "bf16"
num_workers = "auto"
logger = "wandb"
