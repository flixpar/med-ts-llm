DEBUG = false

study = "baseline-models-ecgmit-anom"
model = "gpt4ts" # gpt4ts, dlinear, patchtst, fedformer, timesnet

task = "anomaly_detection"

history_len = 128
pred_len = 128


[data]
dataset = "ECG"
mode = "multivariate"
cols = "all"
normalize = true
step = 128


[training]
epochs = 10
batch_size = 16
optimizer = "adam"
learning_rate = 1e-4
dropout = 0.1
loss = "mse"

eval_metric = "recon_mse"
eval_metric_direction = "min"


[datasets.ECG]
version = "v2"


[tasks.anomaly_detection]
threshold = "auto"
score_metric = "mse"
normalize_by_feature = false
normalize_moving_window = 32


[models.gpt4ts]
d_ff = 768
d_model = 768
gpt_layers = 12
train_mlp = false

[models.gpt4ts.patching]
patch_len = 1
stride = 1


[models.dlinear]
moving_avg = 25
individual = false


[models.patchtst]
e_layers = 3
d_model = 128
d_ff = 256
n_heads = 8
covariate_mode = "independent"

[models.patchtst.patching]
patch_len = 16
stride = 8


[models.fedformer]
d_model = 128
d_ff = 256
n_heads = 8
version = "fourier"
mode_select = "random"
modes = 32
moving_avg = 25
activation = "gelu"
e_layers = 2
d_layers = 1
label_len = 0


[models.timesnet]
e_layers = 3
d_model = 32
d_ff = 32
num_kernels = 6
top_k = 3


[setup]
seed = 0
device = "auto"
dtype = "fp32"
num_workers = "auto"
logger = "wandb"
